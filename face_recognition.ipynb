{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptran1203/face_recognition/blob/master/face_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnmPO1XwiJiJ"
      },
      "source": [
        "from google.colab import drive, output\n",
        "data_loaded = False\n",
        "# drive.mount('/content/drive')\n",
        "BASE_DIR = \"/content/drive/My Drive/face_recognition\"\n",
        "!rm -rf '/content/face_recognition'\n",
        "!git clone https://github.com/ptran1203/face_recognition\n",
        "!pip install face_recognition\n",
        "%cd face_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6AG0_HWub09"
      },
      "source": [
        "from dataloader import *\n",
        "from model import FaceModel, AutoEncoder\n",
        "from utils import *\n",
        "from face_localization import *\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "data_path = \"./dataset/\"\n",
        "\n",
        "class FaceRecognizer(FaceModel):\n",
        "    pass\n",
        "\n",
        "class DataGen(DataGenerator):\n",
        "    pass\n",
        "\n",
        "rst = 128\n",
        "kshot = 10\n",
        "force_reload = 1\n",
        "data_gen = DataGen(data_path, 128, rst, split_option=1,\n",
        "                   test_size=0.2, force_reload_data=force_reload,\n",
        "                   kshot=kshot)\n",
        "fmodel = FaceRecognizer(rst, len(data_gen.classes), lr=1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n4VKSill-xG"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def plot_dist(data, figsize=(30, 20)):\n",
        "    count = dict(Counter(data))\n",
        "    count = list(count.items())\n",
        "    count = sorted(count, key=lambda x: x[1])\n",
        "    df = pd.DataFrame(count)\n",
        "    df.columns = [\"Identities\", \"Count\"]\n",
        "    plt.figure(figsize=figsize)\n",
        "    chart = sns.barplot(\n",
        "        data=df,\n",
        "        x='Identities',\n",
        "        y='Count')\n",
        "\n",
        "    chart.set_xticklabels(chart.get_xticklabels(), rotation=45,\n",
        "                          horizontalalignment='right')\n",
        "\n",
        "plot_dist(np.concatenate([data_gen.labels, data_gen.labels_test, data_gen.labels_support]))\n",
        "# plot_dist(data_gen.labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RccrnaC-2OXe"
      },
      "source": [
        "print(\n",
        "    len(data_gen.y), len(data_gen.y_test)\n",
        ")\n",
        "fmodel.train(data_gen, epochs=100)\n",
        "fmodel.calculate_embeddings(data_gen.x_support, data_gen.y_support)\n",
        "test_acc, pred_wrong = fmodel.evaluate(data_gen.x_test, data_gen.y_test)\n",
        "print(\"Test accuracy: {}%\".format(round(test_acc*100, 2)))\n",
        "# print(\"Incorrect prediction\")\n",
        "# for i in range(0, len(pred_wrong), 10):\n",
        "#     show_images(data_gen.x_test[pred_wrong][i: i+10], denorm=True, deprcs=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81u-b1St9dWf"
      },
      "source": [
        "x, labels = data_gen.x_test, data_gen.labels_test\n",
        "scatter_plot(x, labels,\n",
        "             fmodel.embedding, opt='tsne', plot_img=0,\n",
        "             figsize=(30, 30), image_zoom=0.6,)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhHp7kZ9ZQcC"
      },
      "source": [
        "x, y, labels = data_gen.x_test, data_gen.y_test, data_gen.labels_test\n",
        "print(np.unique(labels))\n",
        "fmodel.calculate_embeddings(x, y)\n",
        "\n",
        "img = get_image_http(\n",
        "    # 'https://img.ti-media.net/wp/uploads/sites/46/2016/01/Jennifer-Lawrence-Anne-Hathaway-Friends-Actresses-Oscars-L-920x690.jpg'\n",
        "    'https://i.insider.com/5d4aa55136e03c2653381c23?width=600&format=jpeg&auto=webp'\n",
        ")\n",
        "\n",
        "def draw_bbox(img, coordinates, text=\"face\", color=(0, 0, 0), offset=35):\n",
        "    \"The pixcel's range should be [0, 255]\"\n",
        "    x, y, w, h = coordinates\n",
        "    cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "    cv2.rectangle(img, (x + offset, y), (x + w , y -25), color, -1)\n",
        "    cv2.putText(img, text, (x + w, y - 10), 0, 0.5, (255, 255, 255))\n",
        "\n",
        "    return img\n",
        "\n",
        "if img is not None:\n",
        "    faces, bboxs = extract_multi_faces(img)\n",
        "    i=0\n",
        "    for face, bbox in zip(faces, bboxs):\n",
        "        i+=1\n",
        "        face = cv2.resize(face, (128,128))\n",
        "        x, y, ex, ey = bbox\n",
        "        pred, prob = fmodel.get_prediction(norm(np.expand_dims(face, 0)),\n",
        "                                    labels)\n",
        "        print(pred, prob)\n",
        "        prob_str = str(int(prob*100))\n",
        "        text = \"{} {}%\".format(pred, prob_str) \\\n",
        "                if prob > 0.3 else \"Undefined\"\n",
        "        offset = 35 if i == 2 else 45\n",
        "        result = draw_bbox(img, (x, y, ex, ey), text,\n",
        "                        (148, 148, 3), offset)\n",
        "\n",
        "    cv2_imshow(result)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t4wo3EFtI-m"
      },
      "source": [
        "import base64\n",
        "import html\n",
        "import io\n",
        "import time\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "def start_input():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 512; //video.videoWidth;\n",
        "      captureCanvas.height = 512; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function takePhoto(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def take_photo(label, img_data):\n",
        "  data = eval_js('takePhoto(\"{}\", \"{}\")'.format(label, img_data))\n",
        "  return data\n",
        "\n",
        "def js_reply_to_image(js_reply):\n",
        "    \"\"\"\n",
        "    input: \n",
        "          js_reply: JavaScript object, contain image from webcam\n",
        "\n",
        "    output: \n",
        "          image_array: image array RGB size 512 x 512 from webcam\n",
        "    \"\"\"\n",
        "    jpeg_bytes = base64.b64decode(js_reply['img'].split(',')[1])\n",
        "    image_PIL = Image.open(io.BytesIO(jpeg_bytes))\n",
        "    image_array = np.array(image_PIL)\n",
        "\n",
        "    return image_array\n",
        "\n",
        "def drawing_array_to_bytes(drawing_array):\n",
        "    \"\"\"\n",
        "    input: \n",
        "          drawing_array: image RGBA size 512 x 512 \n",
        "                              contain bounding box and text from yolo prediction, \n",
        "                              channel A value = 255 if the pixel contains drawing properties (lines, text) \n",
        "                              else channel A value = 0\n",
        "\n",
        "    output: \n",
        "          drawing_bytes: string, encoded from drawing_array\n",
        "    \"\"\"\n",
        "\n",
        "    drawing_PIL = Image.fromarray(drawing_array, 'RGBA')\n",
        "    iobuf = io.BytesIO()\n",
        "    drawing_PIL.save(iobuf, format='png')\n",
        "    drawing_bytes = 'data:image/png;base64,{}'.format((str(base64.b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "    return drawing_bytes"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eIpOIImwEhy",
        "outputId": "a84cf8e3-c643-4be8-fd67-33f4c174f6fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        }
      },
      "source": [
        "start_input()\n",
        "label_html = 'Capturing...'\n",
        "img_data = ''\n",
        "count = 0 \n",
        "size=128\n",
        "\n",
        "frames = []\n",
        "x, y, labels = data_gen.x_support, data_gen.y_support, data_gen.labels_support\n",
        "print(np.unique(labels))\n",
        "fmodel.calculate_embeddings(x, y)\n",
        "\n",
        "from face_recognition import face_locations\n",
        "\n",
        "FACE_SCALE_THRES = (20, 20)\n",
        "\n",
        "\n",
        "def extract_box(image, single=True):\n",
        "    \"\"\"\n",
        "    return <start_Y>, <start_X>, <end_Y>, <end_X>\n",
        "    \"\"\"\n",
        "    boxs = face_locations(image)\n",
        "\n",
        "    if len(boxs) == 0:\n",
        "        return None\n",
        "\n",
        "    if single:\n",
        "        return boxs[0]\n",
        "\n",
        "    return boxs\n",
        "\n",
        "\n",
        "def _get_face(image, start_y, start_x, end_y, end_x):\n",
        "    min_x, max_x = min(start_x, end_x), max(start_x, end_x)\n",
        "    min_y, max_y = min(start_y, end_y), max(start_y, end_y)\n",
        "    face = image[min_y:max_y, min_x:max_x].copy()\n",
        "    fh, fw = face.shape[:2]\n",
        "    # ensure the face width and height are sufficiently large\n",
        "    if fw < FACE_SCALE_THRES[0] or fh < FACE_SCALE_THRES[1]:\n",
        "        return None\n",
        "\n",
        "    return face\n",
        "\n",
        "def extract_multi_faces(image):\n",
        "    h, w = image.shape[:2]\n",
        "\n",
        "    try:\n",
        "        locations = extract_box(image, single=False)\n",
        "    except Exception as e:\n",
        "        return None, None\n",
        "\n",
        "    faces = []\n",
        "    bboxs = []\n",
        "    if locations is not None:\n",
        "        for location in locations:\n",
        "            (start_y, start_x, end_y, end_x) = location\n",
        "            face = _get_face(image, start_y, start_x, end_y, end_x)\n",
        "            if face is not None:\n",
        "                faces.append(face)\n",
        "                bboxs.append((start_x, start_y, end_x - start_x, end_y - start_y))\n",
        "    else:\n",
        "        return None, None\n",
        "    return faces, bboxs\n",
        "\n",
        "while True:\n",
        "    js_reply = take_photo(label_html, img_data)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    image = js_reply_to_image(js_reply)\n",
        "    faces, bboxs = extract_multi_faces(image)\n",
        "    img_array = np.zeros((512,512,4), dtype=np.uint8)   \n",
        "    if faces is not None and len(faces):\n",
        "        for face, bbox in zip(faces, bboxs):\n",
        "            face = cv2.resize(face, (128,128))\n",
        "            x, y, ex, ey = bbox\n",
        "            pred, prob = fmodel.get_prediction(norm(np.expand_dims(face, 0)),\n",
        "                                        labels)\n",
        "            prob_str = str(int(prob*100))\n",
        "            text = \"{} {}%\".format(pred, prob_str) \\\n",
        "                    if prob > 0.3 else \"Undefined\"\n",
        "            result = draw_bbox(img_array, (x, y, ex, ey), text,\n",
        "                            (148, 148, 3))\n",
        "        \n",
        "    img_array[:,:,3] = (img_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    img_data = drawing_array_to_bytes(img_array)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 512; //video.videoWidth;\n",
              "      captureCanvas.height = 512; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function takePhoto(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['Amy_Adams' 'Candice_Accola' 'Fred_Armisen' 'Gao_Yuan_Yuan' 'Iggy_Azalea'\n",
            " 'Quentin_Tarantino' 'Sam_Asghari' 'Will_Arnett' 'charlize_theron'\n",
            " 'dam_vinh_hung' 'george_clooney' 'hoai_linh' 'jet_li' 'ji_chang_wook'\n",
            " 'johnny_depp' 'lee_jong_suk' 'matt_damon' 'megan_fox' 'nha_phuong'\n",
            " 'park_bo_gum' 'park_min_young' 'ryan_gosling' 'son_ye_jin'\n",
            " 'steven_spielberg' 'vin_diesel']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d12d343b7252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mjs_reply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_html\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjs_reply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-c0993d1cd10a>\u001b[0m in \u001b[0;36mtake_photo\u001b[0;34m(label, img_data)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'takePhoto(\"{}\", \"{}\")'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: NotFoundError: Requested device not found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaPTJvS9BZjw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}